{
  "name": "archiver",
  "version": "0.16.0",
  "description": "a streaming interface for archive generation",
  "homepage": "https://github.com/archiverjs/node-archiver",
  "author": {
    "name": "Chris Talkington",
    "url": "http://christalkington.com/"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/archiverjs/node-archiver.git"
  },
  "bugs": {
    "url": "https://github.com/archiverjs/node-archiver/issues"
  },
  "license": "MIT",
  "main": "index.js",
  "files": [
    "index.js",
    "lib"
  ],
  "engines": {
    "node": ">= 0.10.0"
  },
  "scripts": {
    "test": "mocha --reporter dot",
    "bench": "node benchmark/simple/pack-zip.js"
  },
  "dependencies": {
    "async": "~1.4.2",
    "buffer-crc32": "~0.2.1",
    "glob": "~5.0.0",
    "lazystream": "~0.1.0",
    "lodash": "~3.10.0",
    "readable-stream": "~1.0.26",
    "tar-stream": "~1.2.1",
    "zip-stream": "~0.6.0"
  },
  "devDependencies": {
    "chai": "~3.3.0",
    "mocha": "~2.3.3",
    "rimraf": "~2.4.2",
    "mkdirp": "~0.5.0",
    "stream-bench": "~0.1.2",
    "tar": "~2.2.1",
    "yauzl": "~2.3.1"
  },
  "keywords": [
    "archive",
    "archiver",
    "stream",
    "zip",
    "tar"
  ],
  "publishConfig": {
    "registry": "https://registry.npmjs.org/"
  },
  "readme": "# Archiver v0.16.0 [![Build Status](https://travis-ci.org/archiverjs/node-archiver.svg?branch=master)](https://travis-ci.org/archiverjs/node-archiver) [![Build status](https://ci.appveyor.com/api/projects/status/38kqu3yp159nodxe/branch/master?svg=true)](https://ci.appveyor.com/project/ctalkington/node-archiver/branch/master)\r\n\r\na streaming interface for archive generation\r\n\r\n[![NPM](https://nodei.co/npm/archiver.png)](https://nodei.co/npm/archiver/)\r\n\r\n## Install\r\n\r\n```bash\r\nnpm install archiver --save\r\n```\r\n\r\n## Usage\r\n\r\n```js\r\nvar archiver = require('archiver');\r\nvar archive = archiver.create('zip', {}); // or archiver('zip', {});\r\n```\r\n\r\n## API\r\n\r\n#### Transform\r\n\r\nInherits [Transform Stream](http://nodejs.org/api/stream.html#stream_class_stream_transform) methods.\r\n\r\n#### create(format, options)\r\n\r\nCreates an Archiver instance based on the format (zip, tar, etc) passed. Parameters can be passed directly to `Archiver` constructor for convenience.\r\n\r\n#### abort()\r\n\r\nAborts the archiving process, taking a best-effort approach, by:\r\n\r\n* removing any pending queue tasks\r\n* allowing any active queue workers to finish\r\n* detaching internal module pipes\r\n* ending both sides of the Transform stream\r\n\r\n*It will NOT drain any remaining sources.*\r\n\r\n#### append(input, data)\r\n\r\nAppends an input source (text string, buffer, or stream) to the instance. When the instance has received, processed, and emitted the input, the `entry` event is fired.\r\n\r\nReplaced `#addFile` in v0.5.\r\n\r\n```js\r\narchive.append('string', { name:'string.txt' });\r\narchive.append(new Buffer('string'), { name:'buffer.txt' });\r\narchive.append(fs.createReadStream('mydir/file.txt'), { name:'stream.txt' });\r\narchive.append(null, { name:'dir/' });\r\n```\r\n\r\n#### bulk(mappings)\r\n\r\nAppends multiple entries from passed array of src-dest mappings. A [lazystream](https://github.com/jpommerening/node-lazystream) wrapper is used to prevent issues with open file limits.\r\n\r\nGlobbing patterns are supported through use of the bundled [file-utils](https://github.com/SBoudrias/file-utils) module.\r\n\r\nThe `data` property can be set (per src-dest mapping) to define data for matched entries.\r\n\r\n```js\r\narchive.bulk([\r\n  { src: ['mydir/**'], data: { date: new Date() } },\r\n  { src: ['mydir/**'], data: function(data) {\r\n    data.date = new Date();\r\n    return data;\r\n  }},\r\n  { expand: true, cwd: 'mydir', src: ['**'], dest: 'newdir' }\r\n]);\r\n```\r\n\r\nAs of v0.15, the `data` property can also be a function that receives data for each matched entry and is expected to return it after making any desired adjustments.\r\n\r\nFor more detail on this feature, please see [BULK.md](https://github.com/archiverjs/node-archiver/blob/master/BULK.md).\r\n\r\n#### directory(dirpath[, destpath, data])\r\n\r\nAppends a directory and its files, recusively, given its dirpath. This is meant to be a simplier approach to something previously only possible with `bulk`. The use of `destpath` allows one to define a custom destination path within the resulting archive and `data` allows for setting data on each entry appended.\r\n\r\n```js\r\n// mydir/ -> archive.ext/mydir/\r\narchive.directory('mydir');\r\n\r\n// mydir/ -> archive.ext/abc/\r\narchive.directory('mydir', 'abc');\r\n\r\n// mydir/ -> archive.ext/\r\narchive.directory('mydir', false, { date: new Date() });\r\narchive.directory('mydir', false, function(data) {\r\n  data.date = new Date();\r\n  return data;\r\n});\r\n```\r\n\r\nAs of v0.15, the `data` property can also be a function that receives data for each entry and is expected to return it after making any desired adjustments.\r\n\r\n#### file(filepath, data)\r\n\r\nAppends a file given its filepath using a [lazystream](https://github.com/jpommerening/node-lazystream) wrapper to prevent issues with open file limits. When the instance has received, processed, and emitted the file, the `entry` event is fired.\r\n\r\n```js\r\narchive.file('mydir/file.txt', { name:'file.txt' });\r\n```\r\n\r\n#### finalize()\r\n\r\nFinalizes the instance and prevents further appending to the archive structure (queue will continue til drained). The `end`, `close` or `finish` events on the destination stream may fire right after calling this method so you should set listeners beforehand to properly detect stream completion.\r\n\r\n*You must call this method to get a valid archive and end the instance stream.*\r\n\r\n#### pointer()\r\n\r\nReturns the current byte length emitted by archiver. Use this in your end callback to log generated size.\r\n\r\n#### use(plugin)\r\n\r\nAdd a plugin to the middleware stack. Currently this is designed for passing the module to use (replaces registerFormat/setFormat/setModule)\r\n\r\n## Events\r\n\r\nInherits [Transform Stream](http://nodejs.org/api/stream.html#stream_class_stream_transform) events.\r\n\r\n#### entry\r\n\r\nFired when the entry's input has been processed and appended to the archive. Passes entry data as first argument.\r\n\r\n## Zip\r\n\r\n### Options\r\n\r\n#### comment `string`\r\n\r\nSets the zip comment.\r\n\r\n#### statConcurrency `number`\r\n\r\nSets the number of workers used to process the internal fs stat queue. Defaults to 4.\r\n\r\n#### store `boolean`\r\n\r\nIf true, all entries will be archived without compression. Defaults to `false`.\r\n\r\n#### zlib `object`\r\n\r\nPassed to node's [zlib](http://nodejs.org/api/zlib.html#zlib_options) module to control compression. Options may vary by node version.\r\n\r\n### Entry Data\r\n\r\n#### name `string` `required`\r\n\r\nSets the entry name including internal path.\r\n\r\n#### date `string|Date`\r\n\r\nSets the entry date. This can be any valid date string or instance. Defaults to current time in locale.\r\n\r\nWhen using the `bulk` or `file` methods, fs stat data is used as the default value.\r\n\r\n#### store `boolean`\r\n\r\nIf true, this entry will be archived without compression. Defaults to global `store` option.\r\n\r\n#### comment `string`\r\n\r\nSets the entry comment.\r\n\r\n#### mode `number`\r\n\r\nSets the entry permissions. Defaults to octal 0755 (directory) or 0644 (file).\r\n\r\nWhen using the `bulk` or `file` methods, fs stat data is used as the default value.\r\n\r\n#### stats `fs.Stats`\r\n\r\nSets the fs stat data for this entry. This allows for reduction of fs stat calls when stat data is already known.\r\n\r\n## Tar\r\n\r\n### Options\r\n\r\n#### gzip `boolean`\r\n\r\nCompresses the tar archive using gzip, default is false.\r\n\r\n#### gzipOptions `object`\r\n\r\nPassed to node's [zlib](http://nodejs.org/api/zlib.html#zlib_options) module to control compression. Options may vary by node version.\r\n\r\n#### statConcurrency `number`\r\n\r\nSets the number of workers used to process the internal fs stat queue. Defaults to 4.\r\n\r\n### Entry Data\r\n\r\n#### name `string` `required`\r\n\r\nSets the entry name including internal path.\r\n\r\n#### date `string|Date`\r\n\r\nSets the entry date. This can be any valid date string or instance. Defaults to current time in locale.\r\n\r\nWhen using the `bulk` or `file` methods, fs stat data is used as the default value.\r\n\r\n#### mode `number`\r\n\r\nSets the entry permissions. Defaults to octal 0755 (directory) or 0644 (file).\r\n\r\nWhen using the `bulk` or `file` methods, fs stat data is used as the default value.\r\n\r\n#### stats `fs.Stats`\r\n\r\nSets the fs stat data for this entry. This allows for reduction of fs stat calls when stat data is already known.\r\n\r\n## Custom Formats\r\n\r\nArchiver ships with out of the box support for TAR and ZIP archives.\r\n\r\nYou can register additional formats with `registerFormat`.\r\n\r\n_Formats will be changing in the next few releases to implement a middleware approach._\r\n\r\n## Libraries\r\n\r\nArchiver makes use of several libraries/modules to avoid duplication of efforts.\r\n\r\n- [zip-stream](https://npmjs.org/package/zip-stream)\r\n- [tar-stream](https://npmjs.org/package/tar-stream)\r\n\r\n## Things of Interest\r\n\r\n- [Examples](https://github.com/archiverjs/node-archiver/blob/master/examples)\r\n- [Changelog](https://github.com/archiverjs/node-archiver/releases)\r\n- [Contributing](https://github.com/archiverjs/node-archiver/blob/master/CONTRIBUTING.md)\r\n- [MIT License](https://github.com/archiverjs/node-archiver/blob/master/LICENSE-MIT)",
  "readmeFilename": "README.md",
  "_id": "archiver@0.16.0",
  "_shasum": "bb570346899d0865eb77ed66727ab3c634fc1a50",
  "_from": "https://registry.npmjs.org/archiver/-/archiver-0.16.0.tgz",
  "_resolved": "https://registry.npmjs.org/archiver/-/archiver-0.16.0.tgz"
}
